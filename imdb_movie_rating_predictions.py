# -*- coding: utf-8 -*-
"""IMDB Movie rating predictions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tLyPg6MiHKpp9zQwQc6DL_vbBimvx8qS

*Importing the Libraries*
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
import xgboost as xgb
from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, r2_score
from sklearn import metrics

"""*Importing the Dataset*"""

dataset = pd.read_csv('/content/movie_metadata.csv')
pd.set_option('display.max_columns', None)
dataset

dataset.info()

dataset.shape

"""*Checking how many null value present in each column which have to be imputed*"""

dataset.isnull().sum()

"""*Checking the minimum, maximum values as well as mean and standard deviation*"""

dataset.describe()

"""*Counting numbers of movies in each language*"""

dataset['language'].value_counts()

"""*Saving English Movies into a different dataframe for further analysis*"""

eng_dataset = dataset[dataset.language == 'English']
eng_dataset

"""*Storing movies with imdb score equal to 6 or above 6*"""

score = eng_dataset.imdb_score[eng_dataset.imdb_score>=6]
score

"""*Storing movie_titles with imdb score equal to 6 or above 6*"""

name = eng_dataset.movie_title[eng_dataset.imdb_score>=6]
name

"""*Storing movie genre with imdb score equal to 6 or above 6*


"""

genres = eng_dataset.genres[eng_dataset.imdb_score>=6]
genres

"""*Creating a dataframe with score, name and genre of english movies*"""

english_movies = pd.concat([name,genres,score],axis=1)
english_movies

"""***Data visualization***"""

sns.pairplot(data = eng_dataset)

"""*Pie plot for english movies*"""

f,ax=plt.subplots(figsize=(10,20)) 
ax1=plt.subplot(211)
f.suptitle("Imdb score distribution plot")
explode=(0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05)
eng_dataset['imdb_score'].value_counts(ascending=False).head(10).plot(kind='pie',autopct="%0.2f%%",explode=explode,ax=ax1)

"""*Distribution plot for all prices*"""

f,ax=plt.subplots(figsize=(30,10))
ax3=plt.subplot(224)
sns.distplot(eng_dataset['imdb_score'],ax=ax3)

"""*Visualizing the directors names present in the dataset*"""

sns.set_style("darkgrid")
ls = eng_dataset['director_name'].value_counts().head(20).sort_values(ascending=False)
plt.figure(figsize=(15,8))
temp =sns.barplot(ls.index, ls.values, alpha=0.8)
plt.ylabel('COUNT', fontsize=14)
plt.xlabel('Name of Director', fontsize=28)
temp.set_xticklabels(rotation=90,labels=ls.index,fontsize=15)
plt.show()

"""*Visualizing the the barplot of contries and the imdb score*"""

plt.figure(figsize=(20, 6))
sns.barplot(x='country',y='imdb_score',data=eng_dataset);
plt.xticks(rotation=90)

"""*Visualization of the type of content having higher imdb score and the type of movie color present in data*"""

plt.figure(figsize=(20, 6))
sns.barplot(x='content_rating',y='imdb_score',hue='color',data=eng_dataset);
plt.xticks(rotation=90)

"""*Visualization of the type of content rating on X-axis having aspect ratio on Y-axis*"""

plt.figure(figsize=(20, 6))
sns.barplot(x='content_rating',y='aspect_ratio',hue='color',data=eng_dataset);
plt.xticks(rotation=90)

"""*Visualization of the aspect ratio and its imdb score with hue as the color column*"""

plt.figure(figsize=(20, 6))
sns.barplot(x='aspect_ratio',y='imdb_score',hue='color',data=eng_dataset);
plt.xticks(rotation=90)

"""*Removing Null values*"""

eng_dataset = eng_dataset.dropna()
eng_dataset.isnull().sum()
eng_dataset.columns
eng_dataset = eng_dataset.drop(columns=['movie_imdb_link','color','movie_title','facenumber_in_poster', 'plot_keywords',
                    'actor_3_name','movie_imdb_link','aspect_ratio','language'])
eng_dataset

eng_dataset.shape

"""*Label Encoding Categorical data*"""

cat_columns=['content_rating','director_name','genres','actor_1_name','actor_2_name','country']
le=LabelEncoder()
for i in cat_columns:
    eng_dataset[i]=le.fit_transform(eng_dataset[i])
eng_dataset.dtypes

"""*Distribution Plot*"""

rows=4
cols=5
fig, ax=plt.subplots(nrows=rows,ncols=cols,figsize=(20,20))
col=eng_dataset.columns
index=0
for i in range(rows):
    for j in range(cols):
        sns.distplot(eng_dataset[col[index]],ax=ax[i][j])
        index=index+1
        
plt.tight_layout()

"""***Log Transformation***"""

eng_dataset.columns

"""*Selecting all features which are skewed and storing them i n the skewed_features*"""

skewed_features=['director_name', 'num_critic_for_reviews', 'duration',
       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',
       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',
       'num_voted_users', 'cast_total_facebook_likes', 'num_user_for_reviews',
       'country', 'content_rating', 'budget', 'title_year',
       'actor_2_facebook_likes', 'imdb_score', 'movie_facebook_likes']

"""*Applying log transformation on the skewed features*"""

for i in skewed_features:
    eng_dataset[i]=np.log(eng_dataset[i]+1)

"""*Checking the changes in the distribution of data after applying log transformation*"""

rows=4
cols=5
fig, ax=plt.subplots(nrows=rows,ncols=cols,figsize=(20,20))
col=eng_dataset.columns
index=0
for i in range(rows):
    for j in range(cols):
        sns.distplot(eng_dataset[col[index]],ax=ax[i][j])
        index=index+1
        
plt.show()

"""***Splitting dataset***"""

X=eng_dataset.drop(labels=['imdb_score'],axis=1)
Y=eng_dataset['imdb_score']
X.head()

Y.head()

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=0)
print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)

"""***Regression***

*Linear Regression*
"""

lr=LinearRegression()   
lr = lr.fit(X_train,Y_train)
train_pred = lr.predict(X_train)
test_pred = lr.predict(X_test)
RMSE_test = np.sqrt(mean_squared_error(Y_test, test_pred))
RMSE_train= np.sqrt(mean_squared_error(Y_train,train_pred))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',lr.score(X_train, Y_train))
print('RSquared value on test:',lr.score(X_test, Y_test))

"""*Calculating Error*"""

errors = abs(test_pred - Y_test)
mape = 100 * (errors / Y_test)

"""*Calculating Accuracy*"""

accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""***Decision Tree Regressor***"""

dtr = DecisionTreeRegressor(max_depth=9)
dtr.fit(X_train,Y_train)

train_preds = dtr.predict(X_train)

test_preds = dtr.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:', dtr.score(X_train, Y_train))
print('RSquared value on test:', dtr.score(X_test, Y_test))

"""*Calculating error*"""

errors = abs(test_preds - Y_test)

"""*Calculating Accuracy*"""

mape = 100 * (errors / Y_test)
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""***Random Forest Regressor***"""

rfr = RandomForestRegressor().fit(X_train,Y_train)

train_preds1 = rfr.predict(X_train)

test_preds1 = rfr.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds1)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds1)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:', rfr.score(X_train, Y_train))
print('RSquared value on test:', rfr.score(X_test, Y_test))

"""*Calculating Error*"""

errors = abs(test_preds1 - Y_test)

"""*Calculating Accuracy*"""

mape = 100 * (errors / Y_test)
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""***K-Nearest Neighbours***"""

knn=KNeighborsRegressor()
knn.fit(X_train,Y_train)

train_preds2=knn.predict(X_train)

test_preds2=knn.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds2)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds2)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',knn.score(X_train, Y_train))
print('RSquared value on test:',knn.score(X_test, Y_test))

"""*Calculating error*"""

errors = abs(test_preds6 - Y_test)

"""*Calculating accuracy*"""

mape = 100 * (errors / Y_test)
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""***Lasso Regression***"""

from sklearn.linear_model import LassoCV
lasso_reg = LassoCV(cv=10).fit(X_train, Y_train)

train_preds3=lasso_reg.predict(X_train)
#predicting on test
test_preds3=lasso_reg.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds3)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds3)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',lasso_reg.score(X_train, Y_train))
print('RSquared value on test:',lasso_reg.score(X_test, Y_test))

"""*Calculating error*"""

errors = abs(test_preds6 - Y_test)

"""*Calculating accuracy*"""

mape = 100 * (errors / Y_test)
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""***Ridge Regression***"""

from sklearn.linear_model import RidgeCV
ridge_reg = RidgeCV(cv=10).fit(X_train, Y_train)

train_preds4=ridge_reg.predict(X_train)

test_preds4=ridge_reg.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds4)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds4)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',ridge_reg.score(X_train, Y_train))
print('RSquared value on test:',ridge_reg.score(X_test, Y_test))

"""*Calculating error*"""

errors = abs(test_preds6 - Y_test)

"""*Calculating accuracy*"""

mape = 100 * (errors / Y_test)
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""***Elastic Net***"""

from sklearn.linear_model import ElasticNetCV
elastic_net = ElasticNetCV(cv = 10).fit(X_train, Y_train)

train_preds5=elastic_net.predict(X_train)

test_preds5=elastic_net.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds5)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds5)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',elastic_net.score(X_train, Y_train))
print('RSquared value on test:',elastic_net.score(X_test, Y_test))

"""*Calculating error*"""

errors = abs(test_preds6 - Y_test)

"""*Calculating accuracy*"""

mape = 100 * (errors / Y_test)
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')

"""***XG-Boost Regressor***"""

from sklearn.ensemble import GradientBoostingRegressor
xgbr =xgb.XGBRegressor().fit(X_train, Y_train)

train_preds6=xgbr.predict(X_train)

test_preds6=xgbr.predict(X_test)

RMSE_train=(np.sqrt(metrics.mean_squared_error(Y_train,train_preds6)))
RMSE_test=(np.sqrt(metrics.mean_squared_error(Y_test,test_preds6)))
print("RMSE TrainingData = ",str(RMSE_train))
print("RMSE TestData = ",str(RMSE_test))
print('-'*50)
print('RSquared value on train:',xgbr.score(X_train, Y_train))
print('RSquared value on test:',xgbr.score(X_test, Y_test))

"""*Calculating error*"""

errors = abs(test_preds6 - Y_test)

"""*Calculate Accuracy*"""

mape = 100 * (errors / Y_test)
accuracy = 100 - np.mean(mape)
print('Accuracy:', round(accuracy, 2), '%.')